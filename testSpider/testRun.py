from scrapy.cmdline import execute
execute('scrapy crawl qunar'.split())


#2022-07-11 18:44:52 [scrapy.core.engine] INFO: Spider closed (finished)
#这个是成功了啊，ticker.csv中有数据，但是页数肯定是有问题的，哈哈，没有翻页

# spiders 存放爬虫的文件
# items.py 定义数据类型
# middleware.py 存放中间件
# piplines.py 存放数据的有关操作
# settings.py 配置文件
# scrapy.cfg 总的控制文件

#爬行结果
# area,sight,level,price
# 北京·北京·东城区,故宫博物院,5A景区,57.7
# 北京·北京·海淀区,颐和园,5A景区,30
# 北京·北京·东城区,天坛公园,5A景区,14.9
# 北京·北京·海淀区,圆明园,5A景区,9.8
# 北京·北京·延庆县,八达岭长城,5A景区,40
# 北京·北京·大兴区,北京野生动物园,4A景区,144.6
# 北京·北京·西城区,北京动物园,4A景区,14.5
# 北京·北京·通州区,北京环球度假区,,623
# 北京·北京·东城区,中国国家博物馆,,98
# 北京·北京·西城区,北京海洋馆,4A景区,175
# 北京·北京·朝阳区,中国科学技术馆,,30
# 北京·北京·东城区,天安门广场,,0.1
# 北京·北京·海淀区,北京天文馆,4A景区,72
# 北京·北京·西城区,北海公园,4A景区,10
# 北京·北京·西城区,恭王府,5A景区,
